{
  "name": "Jnf neat",
  "tagline": "Actually usable implementation of NEAT",
  "body": "# JNF_NEAT\r\n\r\nMy implementation of Kenneth Stanley and Risto Miikkulainen's NEAT (NeuroEvolution\r\nof Augmenting Topologies, http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf).\r\n\r\nIt focuses (in contrast to other implementations) on\r\n\r\n- Speed - through modern and efficient C++14\r\n- Clean Code - through constant ongoing refactoring and a deep care for aesthetics\r\n- Usability - through beeing able to be used without much knowledge of Neural Networks\r\n\r\n##Foreword\r\n\r\nTODO\r\n\r\n\r\n##Usage\r\nFirst, you have to instanciate a `NeuralNetworkTrainer`. This class will take care of everything. It uses standard training values if not provided with a parameter. If you know what you're doing, you can provide it with a `NeuralNetworkTrainer::RuleSet` instance to tweak the learning process.   \r\n\r\nYou then have to provide an implementation of the `ITrainable` interface. It's methods are\r\n- Update()\r\n- GetOrCalculateFitness()\r\n- ReceiveNetworkOutputs()\r\n- ProvideNetworkWithInputs()\r\n\r\n###Update()\r\nThis method gets called automatically multiple times during training.\r\n> default updatesPerGeneration: 1  \r\n> Imagine this value as **number of actions per lifetime**\r\n\r\nThe actions of your object should take place here. This almost always boils down to **executing the command the Neural Network decides to use**.  \r\n(Remember: You get this Informtion by calling `LoadNeuralNetworkOutputs()`).\r\n\r\n**Example**: Let's say you want to train an artificial player for Super Mario World. This method should then take care of actually pressing the buttons your network want you to. In this specific case, it should also update the whole game for a frame, so enemies and items can react to Mario.\r\n\r\n###GetOrCalculateFitness()\r\nThis method tells the trainer how good this specific instance is compared to others.  \r\nIt gets called automatically when the `ITrainable` object dies \r\n> It's used to generate its offspring, with a fitness score of zero or lower meaning that the genes of this individualare not going to get passed on\r\n\r\n> default minFitness: -2147483646  \r\n> default maxFitness: 100\r\n\r\nNote that in very analog programs such as real world simulations, true perfection should be unreachable\r\n\r\n**Example**: A simulated chess player could have a fitness method implemented like this:\r\n```\r\nunsigned int ChessSim::GetOrCalculateFitness() {\r\n  unsigned int fitness = 0;  \r\n  for (const auto & piece : enemyKilledPieces) {\r\n    fitness += piece.GetImportance();\r\n  }\r\n  for (const auto & piece : ownKilledPieces) {\r\n    fitness -= piece.GetImportance();\r\n  }\r\n  return fitness;\r\n}\r\n```\r\n\r\n###ReceiveNetworkOutputs()\r\nThis method returns the conclusions of your neural network as a series of floats\r\n> default minNeuralCharge = 0.0;  \r\n> default maxNeuralCharge = 1.0;  \r\n> It is **highly** recommended to leave these values like this (see advanced FAQ for details)\r\n\r\nYou'll want to translate these values almost all the time into something your program can work with and store in a member.\r\n\r\n**Example**: TODO\r\n\r\n###ProvideNetworkWithInputs()\r\nTODO\r\n> default minNeuralCharge = 0.0;  \r\n> default maxNeuralCharge = 1.0;  \r\n> It is **highly** recommended to leave these values like this (see advanced FAQ for details)\r\n\r\n**Example**: TODO\r\n\r\n###Full Example\r\n \r\n TODO\r\n \r\n## FAQ\r\n\r\nTODO\r\n\r\n## Advanced FAQ\r\n\r\nTODO\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}